# 增量抓取
1. 如何发现新的数据
    1. 全量抓取的爬虫仍然在继续
        1. 重新启动一个爬虫：一个负责全量抓取，另一个负责增量抓取：使用redis爬虫
        2. 采用优先级队列
    2. 爬虫已经结束
        1. 爬虫已经关闭
            1. 如何发现已经有新的数据待抓取，一旦有了url就需要启动爬虫
        2. 爬虫等待
2. 如何解决已经抓取过的数据
    1. 列表数据已经抓取过之后更新了，要继续抓取
    2. 已经抓取过的数据是否还要继续抓取？更新？
    
结论：基于scrapy-redis进行增量抓取